syntax = "proto3";
package metisfl;

import "metisfl/proto/metis.proto";
import "metisfl/proto/model.proto";
import "metisfl/proto/service_common.proto";

service LearnerService {

  // Unary RPC. Receives a model and evaluates it at its
  // local dataset (any of [train, validation, test]).
  rpc EvaluateModel (EvaluateModelRequest) returns (EvaluateModelResponse) {}

  // Unary RPC. Replies with the health status (beat) of its internal services.
  rpc GetServicesHealthStatus (GetServicesHealthStatusRequest) returns (GetServicesHealthStatusResponse) {}

  // Unary RPC. Assigns task to be trained locally by the learner.
  rpc RunTask (RunTaskRequest) returns (RunTaskResponse) {}

  // Unary rpc. Shuts down all running services of the learner module.
  rpc ShutDown (ShutDownRequest) returns (ShutDownResponse) {}

}

message EvaluateModelRequest {
  // A single model is sent to the evaluation service of the learner.
  Model model = 1;

  // We need to provide the batch size for evaluation because a default value
  // will not work for all models, due to memory limitations, cf. CIFAR images
  // to sentences for NER sequence tagging.
  uint32 batch_size = 2;

  // This is a repeated field since we might request to evaluate a model on more than one datasets.
  enum dataset_to_eval {
    TRAINING = 0;
    TEST = 1;
    VALIDATION = 2;
  }
  repeated dataset_to_eval evaluation_dataset = 3;

  // The list of metrics we want to evaluate the model,
  // e.g., ["accuracy", "f1_score", "confusion_matrix", etc...]
  EvaluationMetrics metrics = 4;
}

message EvaluateModelResponse {
  ModelEvaluations evaluations = 1;
}

message RunTaskRequest {
  // This is the community model sent by the controller to the learner to run the assigned task.
  FederatedModel federated_model = 1;

  // Description of the assigned task.
  LearningTask task = 2;

  // The hyperparameters related to the SGD optimization, i.e., model's optimizer.
  Hyperparameters hyperparameters = 3;
}

message RunTaskResponse {
  Ack ack = 1;
}
